{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a Neural Network classification for predicting market moves based on headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link for data source -https://www.kaggle.com/aaron7sun/stocknews/downloads/stocknews.zip/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import defaultdict\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras import backend as K\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from textblob import TextBlob \n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "\n",
       "                                          Top2  \\\n",
       "0      b'BREAKING: Musharraf to be impeached.'   \n",
       "1  b'Bush puts foot down on Georgian conflict'   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...  ...   \n",
       "1  b'An American citizen living in S.Ossetia blam...  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia ge...   \n",
       "1  b'Israel and the US behind the Georgian aggres...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "\n",
       "                                               Top25  \n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex fo...  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing and viewing dataset\n",
    "# Index(Label) is direction of overall stock market for the day 1 is up 0 is down\n",
    "data = pd.read_csv('./stocknews/Combined_News_DJIA.csv')\n",
    "data.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1987</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Jamaica proposes marijuana dispensers for tour...</td>\n",
       "      <td>Stephen Hawking says pollution and 'stupidity'...</td>\n",
       "      <td>Boris Johnson says he will not run for Tory pa...</td>\n",
       "      <td>Six gay men in Ivory Coast were abused and for...</td>\n",
       "      <td>Switzerland denies citizenship to Muslim immig...</td>\n",
       "      <td>Palestinian terrorist stabs israeli teen girl ...</td>\n",
       "      <td>Puerto Rico will default on $1 billion of debt...</td>\n",
       "      <td>Republic of Ireland fans to be awarded medal f...</td>\n",
       "      <td>...</td>\n",
       "      <td>Googles free wifi at Indian railway stations i...</td>\n",
       "      <td>Mounting evidence suggests 'hobbits' were wipe...</td>\n",
       "      <td>The men who carried out Tuesday's terror attac...</td>\n",
       "      <td>Calls to suspend Saudi Arabia from UN Human Ri...</td>\n",
       "      <td>More Than 100 Nobel Laureates Call Out Greenpe...</td>\n",
       "      <td>British pedophile sentenced to 85 years in US ...</td>\n",
       "      <td>US permitted 1,200 offshore fracks in Gulf of ...</td>\n",
       "      <td>We will be swimming in ridicule - French beach...</td>\n",
       "      <td>UEFA says no minutes of silence for Istanbul v...</td>\n",
       "      <td>Law Enforcement Sources: Gun Used in Paris Ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1988</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>1</td>\n",
       "      <td>A 117-year-old woman in Mexico City finally re...</td>\n",
       "      <td>IMF chief backs Athens as permanent Olympic host</td>\n",
       "      <td>The president of France says if Brexit won, so...</td>\n",
       "      <td>British Man Who Must Give Police 24 Hours' Not...</td>\n",
       "      <td>100+ Nobel laureates urge Greenpeace to stop o...</td>\n",
       "      <td>Brazil: Huge spike in number of police killing...</td>\n",
       "      <td>Austria's highest court annuls presidential el...</td>\n",
       "      <td>Facebook wins privacy case, can track any Belg...</td>\n",
       "      <td>...</td>\n",
       "      <td>The United States has placed Myanmar, Uzbekist...</td>\n",
       "      <td>S&amp;amp;P revises European Union credit rating t...</td>\n",
       "      <td>India gets $1 billion loan from World Bank for...</td>\n",
       "      <td>U.S. sailors detained by Iran spoke too much u...</td>\n",
       "      <td>Mass fish kill in Vietnam solved as Taiwan ste...</td>\n",
       "      <td>Philippines president Rodrigo Duterte urges pe...</td>\n",
       "      <td>Spain arrests three Pakistanis accused of prom...</td>\n",
       "      <td>Venezuela, where anger over food shortages is ...</td>\n",
       "      <td>A Hindu temple worker has been killed by three...</td>\n",
       "      <td>Ozone layer hole seems to be healing - US &amp;amp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Label                                               Top1  \\\n",
       "1987  2016-06-30      1  Jamaica proposes marijuana dispensers for tour...   \n",
       "1988  2016-07-01      1  A 117-year-old woman in Mexico City finally re...   \n",
       "\n",
       "                                                   Top2  \\\n",
       "1987  Stephen Hawking says pollution and 'stupidity'...   \n",
       "1988   IMF chief backs Athens as permanent Olympic host   \n",
       "\n",
       "                                                   Top3  \\\n",
       "1987  Boris Johnson says he will not run for Tory pa...   \n",
       "1988  The president of France says if Brexit won, so...   \n",
       "\n",
       "                                                   Top4  \\\n",
       "1987  Six gay men in Ivory Coast were abused and for...   \n",
       "1988  British Man Who Must Give Police 24 Hours' Not...   \n",
       "\n",
       "                                                   Top5  \\\n",
       "1987  Switzerland denies citizenship to Muslim immig...   \n",
       "1988  100+ Nobel laureates urge Greenpeace to stop o...   \n",
       "\n",
       "                                                   Top6  \\\n",
       "1987  Palestinian terrorist stabs israeli teen girl ...   \n",
       "1988  Brazil: Huge spike in number of police killing...   \n",
       "\n",
       "                                                   Top7  \\\n",
       "1987  Puerto Rico will default on $1 billion of debt...   \n",
       "1988  Austria's highest court annuls presidential el...   \n",
       "\n",
       "                                                   Top8  ...  \\\n",
       "1987  Republic of Ireland fans to be awarded medal f...  ...   \n",
       "1988  Facebook wins privacy case, can track any Belg...  ...   \n",
       "\n",
       "                                                  Top16  \\\n",
       "1987  Googles free wifi at Indian railway stations i...   \n",
       "1988  The United States has placed Myanmar, Uzbekist...   \n",
       "\n",
       "                                                  Top17  \\\n",
       "1987  Mounting evidence suggests 'hobbits' were wipe...   \n",
       "1988  S&amp;P revises European Union credit rating t...   \n",
       "\n",
       "                                                  Top18  \\\n",
       "1987  The men who carried out Tuesday's terror attac...   \n",
       "1988  India gets $1 billion loan from World Bank for...   \n",
       "\n",
       "                                                  Top19  \\\n",
       "1987  Calls to suspend Saudi Arabia from UN Human Ri...   \n",
       "1988  U.S. sailors detained by Iran spoke too much u...   \n",
       "\n",
       "                                                  Top20  \\\n",
       "1987  More Than 100 Nobel Laureates Call Out Greenpe...   \n",
       "1988  Mass fish kill in Vietnam solved as Taiwan ste...   \n",
       "\n",
       "                                                  Top21  \\\n",
       "1987  British pedophile sentenced to 85 years in US ...   \n",
       "1988  Philippines president Rodrigo Duterte urges pe...   \n",
       "\n",
       "                                                  Top22  \\\n",
       "1987  US permitted 1,200 offshore fracks in Gulf of ...   \n",
       "1988  Spain arrests three Pakistanis accused of prom...   \n",
       "\n",
       "                                                  Top23  \\\n",
       "1987  We will be swimming in ridicule - French beach...   \n",
       "1988  Venezuela, where anger over food shortages is ...   \n",
       "\n",
       "                                                  Top24  \\\n",
       "1987  UEFA says no minutes of silence for Istanbul v...   \n",
       "1988  A Hindu temple worker has been killed by three...   \n",
       "\n",
       "                                                  Top25  \n",
       "1987  Law Enforcement Sources: Gun Used in Paris Ter...  \n",
       "1988  Ozone layer hole seems to be healing - US &amp...  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1065\n",
       "0     924\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating number of positive and negative days and sniffing for null values\n",
    "data['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1989, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describing the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old data frame length: 1989 \n",
      "New data frame length: 1986 \n",
      "Number of rows with at least 1 NA value:  3\n"
     ]
    }
   ],
   "source": [
    "#Data cleaning\n",
    "#data.isnull().sum()\n",
    "# making new data frame with dropped NA values \n",
    "new_data = data.dropna(axis = 0, how ='any') \n",
    "  \n",
    "# comparing sizes of data frames \n",
    "print(\"Old data frame length:\", len(data), \"\\nNew data frame length:\",  \n",
    "       len(new_data), \"\\nNumber of rows with at least 1 NA value: \", \n",
    "       (len(data)-len(new_data))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data set into test and train sets\n",
    "#train = data[data['Date'] < '2012-07-20']\n",
    "#test = data[data['Date'] > '2012-07-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data set into test and train sets\n",
    "train = new_data[new_data['Date'] < '2015-01-01']\n",
    "#test = new_data[new_data['Date'] > '2015-01-01']\n",
    "test = new_data[new_data['Date'] > '2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 400)\n",
      "(1608, 400)\n"
     ]
    }
   ],
   "source": [
    "#Vectorizing text using Term Frequency-Inverse Document Frequency\n",
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "advancedvectorizer = TfidfVectorizer( min_df=0.04, max_df=0.3, max_features = 200000, ngram_range = (2, 2))\n",
    "trainheadlines = []\n",
    "for row in range(0,len(train.index)):\n",
    "    trainheadlines.append(' '.join(str(x) for x in train.iloc[row,2:27]))\n",
    "advancedtrain = advancedvectorizer.fit_transform(trainheadlines)\n",
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "print(advancedtest.shape)\n",
    "print(advancedtrain.shape)\n",
    "#print(advancedtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 14:10:17.222471 140736230503296 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0924 14:10:17.248749 140736230503296 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0924 14:10:17.252400 140736230503296 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0924 14:10:17.270783 140736230503296 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0924 14:10:17.281188 140736230503296 deprecation.py:506] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0924 14:10:17.378617 140736230503296 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0924 14:10:17.407844 140736230503296 deprecation_wrapper.py:119] From /anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "W0924 14:10:17.559721 140736230503296 deprecation.py:323] From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/2\n",
      "1366/1366 [==============================] - 1s 397us/step - loss: 0.6952 - val_loss: 0.6853\n",
      "Epoch 2/2\n",
      "1366/1366 [==============================] - 0s 190us/step - loss: 0.6789 - val_loss: 0.6872\n",
      "Generating test predictions...\n"
     ]
    }
   ],
   "source": [
    "X_train = advancedtrain.toarray()\n",
    "X_test = advancedtest.toarray()\n",
    "\n",
    "#print('X_train shape:', X_train.shape)\n",
    "#print('X_test shape:', X_test.shape)\n",
    "y_train = np.array(train[\"Label\"])\n",
    "y_test = np.array(test[\"Label\"])\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "# pre-processing: divide by max and substract mean\n",
    "#scale = np.max(X_train)\n",
    "#X_train /= scale\n",
    "#X_test /= scale\n",
    "\n",
    "#mean = np.mean(X_train)\n",
    "#X_train -= mean\n",
    "#X_test -= mean\n",
    "\n",
    "#Defining input dimension\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=input_dim))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# we'll use categorical xent for the loss, and RMSprop as the optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "print(\"Training...\")\n",
    "model.fit(X_train, Y_train, nb_epoch=2, batch_size=16, validation_split=0.15)\n",
    "\n",
    "print(\"Generating test predictions...\")\n",
    "preds14 = model.predict_classes(X_test, verbose=0)\n",
    "acc14 = accuracy_score(test[\"Label\"], preds14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5529100529100529"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 1s 493us/step - loss: 0.6924 - acc: 0.5264 - val_loss: 0.6851 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 0s 209us/step - loss: 0.6774 - acc: 0.5747 - val_loss: 0.6824 - val_acc: 0.5331\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 0s 220us/step - loss: 0.5969 - acc: 0.6867 - val_loss: 0.7242 - val_acc: 0.5537\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 0s 218us/step - loss: 0.4036 - acc: 0.8397 - val_loss: 0.9247 - val_acc: 0.5331\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 0s 214us/step - loss: 0.1542 - acc: 0.9583 - val_loss: 1.3199 - val_acc: 0.5372\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 222us/step - loss: 0.0375 - acc: 0.9956 - val_loss: 1.8427 - val_acc: 0.5124\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 0s 213us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 2.1067 - val_acc: 0.5248\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 0s 214us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 2.2927 - val_acc: 0.5165\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 0s 210us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 2.4277 - val_acc: 0.5289\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 0s 241us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 2.5377 - val_acc: 0.5207\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 0s 218us/step - loss: 7.4219e-04 - acc: 1.0000 - val_loss: 2.6314 - val_acc: 0.5248\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 210us/step - loss: 5.6950e-04 - acc: 1.0000 - val_loss: 2.7130 - val_acc: 0.5289\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 0s 225us/step - loss: 4.5110e-04 - acc: 1.0000 - val_loss: 2.7874 - val_acc: 0.5248\n",
      "Epoch 14/20\n",
      "1366/1366 [==============================] - 0s 209us/step - loss: 3.6452e-04 - acc: 1.0000 - val_loss: 2.8533 - val_acc: 0.5207\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 0s 210us/step - loss: 2.9969e-04 - acc: 1.0000 - val_loss: 2.9159 - val_acc: 0.5207\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 0s 221us/step - loss: 2.5022e-04 - acc: 1.0000 - val_loss: 2.9705 - val_acc: 0.5248\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 0s 198us/step - loss: 2.1133e-04 - acc: 1.0000 - val_loss: 3.0220 - val_acc: 0.5248\n",
      "Epoch 18/20\n",
      "1366/1366 [==============================] - 0s 216us/step - loss: 1.8011e-04 - acc: 1.0000 - val_loss: 3.0735 - val_acc: 0.5207\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 201us/step - loss: 1.5497e-04 - acc: 1.0000 - val_loss: 3.1199 - val_acc: 0.5248\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 0s 228us/step - loss: 1.3396e-04 - acc: 1.0000 - val_loss: 3.1631 - val_acc: 0.5289\n",
      "1608/1608 [==============================] - 0s 34us/step\n",
      "Accuracy: 92.91\n"
     ]
    }
   ],
   "source": [
    "#Trying another model to improve accuracy, changing loss function and optimizer\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('./stocknews/Combined_News_DJIA.csv')\n",
    "# split into input (X) and output (y) variables\n",
    "# define the keras model\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(64, input_dim=400, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model1.add(Dense(48, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model1.add(Dense(2, activation='softmax'))\n",
    "# compile the keras model\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model1.fit(X_train, Y_train, epochs=20, batch_size=10, validation_split= 0.15)\n",
    "#model.fit(X_train, Y_train, nb_epoch=2, batch_size=16, validation_split=0.15)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model1.evaluate(X_train, Y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 76us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.0328142844810686, 0.5582010578856897]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the performance of model 1\n",
    "model1.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 76,  57],\n",
       "       [110, 135]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = model1.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_pred, y_test)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CASES\n",
    "#Try Alternates. Use L2 regularization and optimize lambda penalty function. Grid search\n",
    "#Try Alternates. Use L1 or the combined L1L2 methods instead of L2 regularization.\n",
    "#Regularize Output Layer. - Regularize the output layer of the model and compare the results. (Dropout)\n",
    "# Regularize Bias. Regularize the bias weight and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 1s 747us/step - loss: 1.1991 - acc: 0.5359 - val_loss: 0.9077 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 0s 236us/step - loss: 0.8038 - acc: 0.5366 - val_loss: 0.7334 - val_acc: 0.5579\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 0s 229us/step - loss: 0.7127 - acc: 0.5373 - val_loss: 0.6970 - val_acc: 0.5579\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 0s 237us/step - loss: 0.6960 - acc: 0.5381 - val_loss: 0.6902 - val_acc: 0.5579\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 0s 227us/step - loss: 0.6925 - acc: 0.5381 - val_loss: 0.6882 - val_acc: 0.5579\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 236us/step - loss: 0.6904 - acc: 0.5381 - val_loss: 0.6876 - val_acc: 0.5579\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 0s 237us/step - loss: 0.6912 - acc: 0.5381 - val_loss: 0.6877 - val_acc: 0.5579\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 0s 234us/step - loss: 0.6907 - acc: 0.5381 - val_loss: 0.6876 - val_acc: 0.5579\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 0s 230us/step - loss: 0.6909 - acc: 0.5381 - val_loss: 0.6877 - val_acc: 0.5579\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 0s 239us/step - loss: 0.6910 - acc: 0.5381 - val_loss: 0.6878 - val_acc: 0.5579\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 0s 233us/step - loss: 0.6906 - acc: 0.5381 - val_loss: 0.6876 - val_acc: 0.5579\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 240us/step - loss: 0.6906 - acc: 0.5381 - val_loss: 0.6875 - val_acc: 0.5579\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 0s 241us/step - loss: 0.6907 - acc: 0.5381 - val_loss: 0.6876 - val_acc: 0.5579\n",
      "Epoch 14/20\n",
      "1366/1366 [==============================] - 0s 228us/step - loss: 0.6908 - acc: 0.5381 - val_loss: 0.6875 - val_acc: 0.5579\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 0s 234us/step - loss: 0.6905 - acc: 0.5381 - val_loss: 0.6872 - val_acc: 0.5579\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 0s 234us/step - loss: 0.6903 - acc: 0.5381 - val_loss: 0.6873 - val_acc: 0.5579\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 0s 232us/step - loss: 0.6903 - acc: 0.5381 - val_loss: 0.6871 - val_acc: 0.5579\n",
      "Epoch 18/20\n",
      "1366/1366 [==============================] - 0s 231us/step - loss: 0.6904 - acc: 0.5381 - val_loss: 0.6871 - val_acc: 0.5579\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 224us/step - loss: 0.6905 - acc: 0.5381 - val_loss: 0.6874 - val_acc: 0.5579\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 0s 235us/step - loss: 0.6905 - acc: 0.5381 - val_loss: 0.6874 - val_acc: 0.5579\n",
      "1608/1608 [==============================] - 0s 32us/step\n",
      "Accuracy: 54.10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Case 1 and 3 combined: L2 regularization techniques with droupouts\n",
    "#Trying another model to improve accuracy\n",
    "from keras import regularizers\n",
    "from matplotlib import pyplot\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('./stocknews/Combined_News_DJIA.csv')\n",
    "# split into input (X) and output (y) variables\n",
    "# define the keras model\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(64, input_dim=400, activation='relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(48, activation='relu', kernel_regularizer=regularizers.l2(0.01) ))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "# compile the keras model\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "history=model2.fit(X_train, Y_train, epochs=20, batch_size=10, validation_split= 0.15)\n",
    "#model.fit(X_train, Y_train, nb_epoch=2, batch_size=16, validation_split=0.15)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model2.evaluate(X_train, Y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "#plotting accuracy\n",
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 43us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [186, 192]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating the performance of the second model\n",
    "model2.evaluate(X_test,Y_test)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "y_pred2 = np.argmax(y_pred2, axis=1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm2 = confusion_matrix(y_pred2, y_test)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 1s 721us/step - loss: 5.0287 - acc: 0.5315 - val_loss: 2.1114 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 0s 231us/step - loss: 1.2862 - acc: 0.5381 - val_loss: 0.8435 - val_acc: 0.5579\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 0s 255us/step - loss: 0.7489 - acc: 0.5381 - val_loss: 0.6992 - val_acc: 0.5579\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 0s 227us/step - loss: 0.6948 - acc: 0.5381 - val_loss: 0.6883 - val_acc: 0.5579\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 0s 230us/step - loss: 0.6908 - acc: 0.5381 - val_loss: 0.6872 - val_acc: 0.5579\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 247us/step - loss: 0.6905 - acc: 0.5381 - val_loss: 0.6870 - val_acc: 0.5579\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 0s 236us/step - loss: 0.6906 - acc: 0.5381 - val_loss: 0.6874 - val_acc: 0.5579\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 0s 226us/step - loss: 0.6904 - acc: 0.5381 - val_loss: 0.6872 - val_acc: 0.5579\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 0s 250us/step - loss: 0.6910 - acc: 0.5381 - val_loss: 0.6875 - val_acc: 0.5579\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 0s 227us/step - loss: 0.6902 - acc: 0.5381 - val_loss: 0.6872 - val_acc: 0.5579\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 0s 233us/step - loss: 0.6906 - acc: 0.5381 - val_loss: 0.6872 - val_acc: 0.5579\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 238us/step - loss: 0.6906 - acc: 0.5381 - val_loss: 0.6874 - val_acc: 0.5579\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 0s 225us/step - loss: 0.6904 - acc: 0.5381 - val_loss: 0.6871 - val_acc: 0.5579\n",
      "Epoch 14/20\n",
      "1366/1366 [==============================] - 0s 222us/step - loss: 0.6909 - acc: 0.5381 - val_loss: 0.6874 - val_acc: 0.5579\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 0s 207us/step - loss: 0.6907 - acc: 0.5381 - val_loss: 0.6875 - val_acc: 0.5579\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 0s 229us/step - loss: 0.6902 - acc: 0.5381 - val_loss: 0.6872 - val_acc: 0.5579\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 0s 227us/step - loss: 0.6898 - acc: 0.5381 - val_loss: 0.6872 - val_acc: 0.5579\n",
      "Epoch 18/20\n",
      "1366/1366 [==============================] - 0s 228us/step - loss: 0.6901 - acc: 0.5381 - val_loss: 0.6873 - val_acc: 0.5579\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 233us/step - loss: 0.6906 - acc: 0.5381 - val_loss: 0.6871 - val_acc: 0.5579\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 0s 225us/step - loss: 0.6907 - acc: 0.5381 - val_loss: 0.6873 - val_acc: 0.5579\n",
      "1608/1608 [==============================] - 0s 26us/step\n",
      "378/378 [==============================] - 0s 36us/step\n",
      "Accuracy: 54.10\n",
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 1s 793us/step - loss: 1.2109 - acc: 0.5102 - val_loss: 0.9217 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 0s 233us/step - loss: 0.8109 - acc: 0.5381 - val_loss: 0.7366 - val_acc: 0.5579\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 0s 254us/step - loss: 0.7156 - acc: 0.5381 - val_loss: 0.6987 - val_acc: 0.5579\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 0s 241us/step - loss: 0.6959 - acc: 0.5381 - val_loss: 0.6897 - val_acc: 0.5579\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 0s 244us/step - loss: 0.6923 - acc: 0.5381 - val_loss: 0.6884 - val_acc: 0.5579\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 242us/step - loss: 0.6919 - acc: 0.5381 - val_loss: 0.6880 - val_acc: 0.5579\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 0s 243us/step - loss: 0.6909 - acc: 0.5381 - val_loss: 0.6879 - val_acc: 0.5579\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 0s 251us/step - loss: 0.6911 - acc: 0.5381 - val_loss: 0.6875 - val_acc: 0.5579\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 0s 253us/step - loss: 0.6910 - acc: 0.5381 - val_loss: 0.6880 - val_acc: 0.5579\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 0s 238us/step - loss: 0.6905 - acc: 0.5381 - val_loss: 0.6875 - val_acc: 0.5579\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 0s 236us/step - loss: 0.6903 - acc: 0.5381 - val_loss: 0.6876 - val_acc: 0.5579\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 237us/step - loss: 0.6910 - acc: 0.5381 - val_loss: 0.6874 - val_acc: 0.5579\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 0s 239us/step - loss: 0.6902 - acc: 0.5381 - val_loss: 0.6873 - val_acc: 0.5579\n",
      "Epoch 14/20\n",
      "1366/1366 [==============================] - 0s 240us/step - loss: 0.6908 - acc: 0.5381 - val_loss: 0.6876 - val_acc: 0.5579\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 0s 248us/step - loss: 0.6905 - acc: 0.5381 - val_loss: 0.6874 - val_acc: 0.5579\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 0s 239us/step - loss: 0.6905 - acc: 0.5381 - val_loss: 0.6876 - val_acc: 0.5579\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 0s 250us/step - loss: 0.6907 - acc: 0.5381 - val_loss: 0.6875 - val_acc: 0.5579\n",
      "Epoch 18/20\n",
      "1366/1366 [==============================] - 0s 253us/step - loss: 0.6914 - acc: 0.5381 - val_loss: 0.6874 - val_acc: 0.5579\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 237us/step - loss: 0.6908 - acc: 0.5381 - val_loss: 0.6875 - val_acc: 0.5579\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 0s 238us/step - loss: 0.6905 - acc: 0.5381 - val_loss: 0.6872 - val_acc: 0.5579\n",
      "1608/1608 [==============================] - 0s 28us/step\n",
      "378/378 [==============================] - 0s 41us/step\n",
      "Accuracy: 54.10\n",
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 1s 861us/step - loss: 0.7727 - acc: 0.5139 - val_loss: 0.7551 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 0s 254us/step - loss: 0.7476 - acc: 0.5417 - val_loss: 0.7420 - val_acc: 0.5702\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 0s 252us/step - loss: 0.7374 - acc: 0.5490 - val_loss: 0.7277 - val_acc: 0.5579\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 0s 249us/step - loss: 0.7268 - acc: 0.5439 - val_loss: 0.7246 - val_acc: 0.5826\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 0s 257us/step - loss: 0.7110 - acc: 0.5608 - val_loss: 0.7161 - val_acc: 0.5785\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 243us/step - loss: 0.6860 - acc: 0.6083 - val_loss: 0.7238 - val_acc: 0.5165\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 1s 418us/step - loss: 0.6514 - acc: 0.6823 - val_loss: 0.7481 - val_acc: 0.5165\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 0s 353us/step - loss: 0.5960 - acc: 0.7204 - val_loss: 0.7993 - val_acc: 0.5537\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 0s 354us/step - loss: 0.5475 - acc: 0.7621 - val_loss: 0.8450 - val_acc: 0.5620\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 1s 486us/step - loss: 0.4779 - acc: 0.8009 - val_loss: 0.9669 - val_acc: 0.5537\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 1s 436us/step - loss: 0.4038 - acc: 0.8580 - val_loss: 1.0180 - val_acc: 0.5620\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 330us/step - loss: 0.3663 - acc: 0.8704 - val_loss: 1.1141 - val_acc: 0.5702\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 1s 384us/step - loss: 0.3180 - acc: 0.8982 - val_loss: 1.2633 - val_acc: 0.5702\n",
      "Epoch 14/20\n",
      "1366/1366 [==============================] - 0s 334us/step - loss: 0.2775 - acc: 0.9114 - val_loss: 1.3697 - val_acc: 0.5537\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 1s 512us/step - loss: 0.2359 - acc: 0.9341 - val_loss: 1.5915 - val_acc: 0.5620\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 1s 389us/step - loss: 0.2010 - acc: 0.9473 - val_loss: 1.7311 - val_acc: 0.5413\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 1s 473us/step - loss: 0.1823 - acc: 0.9524 - val_loss: 1.7709 - val_acc: 0.5579\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366/1366 [==============================] - 0s 320us/step - loss: 0.1770 - acc: 0.9517 - val_loss: 1.8236 - val_acc: 0.5496\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 315us/step - loss: 0.1743 - acc: 0.9561 - val_loss: 2.0751 - val_acc: 0.5744\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 0s 283us/step - loss: 0.1636 - acc: 0.9619 - val_loss: 1.8975 - val_acc: 0.5496\n",
      "1608/1608 [==============================] - 0s 62us/step\n",
      "378/378 [==============================] - 0s 50us/step\n",
      "Accuracy: 54.10\n",
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 2s 1ms/step - loss: 0.7025 - acc: 0.4985 - val_loss: 0.6954 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 1s 468us/step - loss: 0.6981 - acc: 0.5381 - val_loss: 0.6957 - val_acc: 0.5579\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 1s 471us/step - loss: 0.6995 - acc: 0.5322 - val_loss: 0.6948 - val_acc: 0.5579\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 0s 341us/step - loss: 0.6964 - acc: 0.5381 - val_loss: 0.6940 - val_acc: 0.5620\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 0s 239us/step - loss: 0.6842 - acc: 0.5600 - val_loss: 0.6915 - val_acc: 0.5537\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 234us/step - loss: 0.6760 - acc: 0.5937 - val_loss: 0.6914 - val_acc: 0.5537\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 0s 255us/step - loss: 0.6479 - acc: 0.6471 - val_loss: 0.7056 - val_acc: 0.5702\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 0s 240us/step - loss: 0.5858 - acc: 0.7225 - val_loss: 0.7524 - val_acc: 0.5207\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 0s 236us/step - loss: 0.5310 - acc: 0.7562 - val_loss: 0.8066 - val_acc: 0.5331\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 0s 257us/step - loss: 0.4486 - acc: 0.8177 - val_loss: 0.8960 - val_acc: 0.5165\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 0s 236us/step - loss: 0.3955 - acc: 0.8404 - val_loss: 1.0265 - val_acc: 0.5413\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 249us/step - loss: 0.3396 - acc: 0.8697 - val_loss: 1.0763 - val_acc: 0.5124\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 0s 259us/step - loss: 0.2787 - acc: 0.8939 - val_loss: 1.2084 - val_acc: 0.5331\n",
      "Epoch 14/20\n",
      "1366/1366 [==============================] - 0s 239us/step - loss: 0.2404 - acc: 0.9122 - val_loss: 1.4460 - val_acc: 0.5248\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 0s 250us/step - loss: 0.1995 - acc: 0.9261 - val_loss: 1.5883 - val_acc: 0.5083\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 0s 244us/step - loss: 0.2001 - acc: 0.9246 - val_loss: 1.6183 - val_acc: 0.5289\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 0s 248us/step - loss: 0.1678 - acc: 0.9414 - val_loss: 1.7958 - val_acc: 0.5372\n",
      "Epoch 18/20\n",
      "1366/1366 [==============================] - 0s 254us/step - loss: 0.1574 - acc: 0.9502 - val_loss: 1.9733 - val_acc: 0.5455\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 240us/step - loss: 0.1350 - acc: 0.9495 - val_loss: 2.1006 - val_acc: 0.4917\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 0s 237us/step - loss: 0.1487 - acc: 0.9531 - val_loss: 2.0136 - val_acc: 0.5000\n",
      "1608/1608 [==============================] - 0s 30us/step\n",
      "378/378 [==============================] - 0s 43us/step\n",
      "Accuracy: 54.10\n",
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 1s 1ms/step - loss: 0.6950 - acc: 0.5139 - val_loss: 0.6894 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 0s 274us/step - loss: 0.6923 - acc: 0.5381 - val_loss: 0.6890 - val_acc: 0.5579\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 0s 261us/step - loss: 0.6917 - acc: 0.5359 - val_loss: 0.6882 - val_acc: 0.5579\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 0s 270us/step - loss: 0.6875 - acc: 0.5469 - val_loss: 0.6878 - val_acc: 0.5579\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 0s 255us/step - loss: 0.6877 - acc: 0.5527 - val_loss: 0.6879 - val_acc: 0.5579\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 258us/step - loss: 0.6827 - acc: 0.5520 - val_loss: 0.6863 - val_acc: 0.5537\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 0s 265us/step - loss: 0.6724 - acc: 0.6025 - val_loss: 0.6849 - val_acc: 0.5537\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 0s 270us/step - loss: 0.6470 - acc: 0.6303 - val_loss: 0.6897 - val_acc: 0.5702\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 0s 261us/step - loss: 0.6065 - acc: 0.6823 - val_loss: 0.7002 - val_acc: 0.5702\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 0s 270us/step - loss: 0.5571 - acc: 0.7284 - val_loss: 0.7279 - val_acc: 0.5868\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 0s 255us/step - loss: 0.4836 - acc: 0.7994 - val_loss: 0.8397 - val_acc: 0.5537\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 256us/step - loss: 0.4197 - acc: 0.8287 - val_loss: 0.8439 - val_acc: 0.5702\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 0s 289us/step - loss: 0.3365 - acc: 0.8770 - val_loss: 0.9934 - val_acc: 0.5661\n",
      "Epoch 14/20\n",
      "1366/1366 [==============================] - 0s 252us/step - loss: 0.2819 - acc: 0.8968 - val_loss: 1.0951 - val_acc: 0.5620\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 0s 254us/step - loss: 0.2388 - acc: 0.9209 - val_loss: 1.2445 - val_acc: 0.5620\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 0s 276us/step - loss: 0.2478 - acc: 0.9107 - val_loss: 1.2862 - val_acc: 0.5083\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 0s 259us/step - loss: 0.1725 - acc: 0.9422 - val_loss: 1.4954 - val_acc: 0.5413\n",
      "Epoch 18/20\n",
      "1366/1366 [==============================] - 0s 270us/step - loss: 0.1578 - acc: 0.9451 - val_loss: 1.5127 - val_acc: 0.5372\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 259us/step - loss: 0.1385 - acc: 0.9502 - val_loss: 1.6006 - val_acc: 0.5496\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 1s 383us/step - loss: 0.1230 - acc: 0.9575 - val_loss: 1.6920 - val_acc: 0.5331\n",
      "1608/1608 [==============================] - 0s 57us/step\n",
      "378/378 [==============================] - 0s 48us/step\n",
      "Accuracy: 54.10\n",
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 2s 1ms/step - loss: 0.6954 - acc: 0.5066 - val_loss: 0.6887 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 0s 272us/step - loss: 0.6923 - acc: 0.5286 - val_loss: 0.6893 - val_acc: 0.5579\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 0s 272us/step - loss: 0.6882 - acc: 0.5344 - val_loss: 0.6880 - val_acc: 0.5537\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 0s 266us/step - loss: 0.6844 - acc: 0.5600 - val_loss: 0.6876 - val_acc: 0.5702\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 0s 272us/step - loss: 0.6722 - acc: 0.5842 - val_loss: 0.6876 - val_acc: 0.5372\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 263us/step - loss: 0.6515 - acc: 0.6083 - val_loss: 0.6970 - val_acc: 0.5124\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 0s 262us/step - loss: 0.6245 - acc: 0.6391 - val_loss: 0.7136 - val_acc: 0.5413\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 0s 279us/step - loss: 0.5668 - acc: 0.7240 - val_loss: 0.7685 - val_acc: 0.5909\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 0s 263us/step - loss: 0.5098 - acc: 0.7533 - val_loss: 0.8242 - val_acc: 0.5785\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 0s 263us/step - loss: 0.4627 - acc: 0.7870 - val_loss: 0.8588 - val_acc: 0.5661\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 0s 257us/step - loss: 0.3950 - acc: 0.8265 - val_loss: 0.9752 - val_acc: 0.5620\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 271us/step - loss: 0.3219 - acc: 0.8690 - val_loss: 1.1849 - val_acc: 0.5496\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 0s 268us/step - loss: 0.2557 - acc: 0.8939 - val_loss: 1.3322 - val_acc: 0.5496\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1366/1366 [==============================] - 0s 258us/step - loss: 0.2419 - acc: 0.9122 - val_loss: 1.3493 - val_acc: 0.5826\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 0s 242us/step - loss: 0.1797 - acc: 0.9312 - val_loss: 1.7336 - val_acc: 0.5702\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 0s 266us/step - loss: 0.1920 - acc: 0.9297 - val_loss: 1.5858 - val_acc: 0.5620\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 0s 242us/step - loss: 0.1455 - acc: 0.9517 - val_loss: 1.8154 - val_acc: 0.5785\n",
      "Epoch 18/20\n",
      "1366/1366 [==============================] - 0s 240us/step - loss: 0.1423 - acc: 0.9531 - val_loss: 1.7882 - val_acc: 0.5744\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 246us/step - loss: 0.1214 - acc: 0.9583 - val_loss: 1.8695 - val_acc: 0.5620\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 0s 255us/step - loss: 0.1202 - acc: 0.9605 - val_loss: 2.1212 - val_acc: 0.5950\n",
      "1608/1608 [==============================] - 0s 33us/step\n",
      "378/378 [==============================] - 0s 51us/step\n",
      "Accuracy: 54.10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Case 1 continued\n",
    "#Checking to see if adjusting the l2 regularization parameter can help improve the calculation\n",
    "#optimizing the regularization hyperparameter value using grid search to determine best l2 parameter\n",
    "\n",
    "#L2 regularization techniques\n",
    "#Trying another model to improve accuracy\n",
    "from keras import regularizers\n",
    "from matplotlib import pyplot\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('./stocknews/Combined_News_DJIA.csv')\n",
    "# split into input (X) and output (y) variables\n",
    "# define the keras model\n",
    "# grid search values\n",
    "values = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "all_train, all_test = list(), list()\n",
    "for param in values:\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(64, input_dim=400, activation='relu'))\n",
    "    model3.add(Dropout(0.5))\n",
    "    model3.add(Dense(48, activation='relu', kernel_regularizer=regularizers.l2(param) ))\n",
    "    model3.add(Dropout(0.5))\n",
    "    model3.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(param)))\n",
    "    model3.add(Dropout(0.5))\n",
    "    model3.add(Dense(2, activation='softmax'))\n",
    "# compile the keras model\n",
    "    model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "    history1=model3.fit(X_train, Y_train, epochs=20, batch_size=10, validation_split= 0.15)\n",
    "#model.fit(X_train, Y_train, nb_epoch=2, batch_size=16, validation_split=0.15)\n",
    "# evaluate the keras model\n",
    "    _, train_acc = model3.evaluate(X_train, Y_train)\n",
    "    _, test_acc = model3.evaluate(X_test, Y_test)\n",
    "    print('Accuracy: %.2f' % (accuracy*100))\n",
    "    all_train.append(train_acc)\n",
    "    all_test.append(test_acc)\n",
    "#plotting accuracy\n",
    "#pyplot.plot(history.history['acc'], label='train')\n",
    "#pyplot.plot(history.history['val_acc'], label='test')\n",
    "pyplot.semilogx(values, all_train, label='train', marker='o')\n",
    "pyplot.semilogx(values, all_test, label='test', marker='o')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 61us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.012203299810016, 0.5846560849714532]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 69,  40],\n",
       "       [117, 152]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3 = model3.predict(X_test)\n",
    "y_pred3 = np.argmax(y_pred3, axis=1)\n",
    "cm3 = confusion_matrix(y_pred3, y_test)\n",
    "cm3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 2s 1ms/step - loss: 311.8764 - acc: 0.5381 - val_loss: 113.1344 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 0s 305us/step - loss: 33.4992 - acc: 0.5381 - val_loss: 1.5243 - val_acc: 0.5579\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 0s 258us/step - loss: 1.2984 - acc: 0.5381 - val_loss: 1.2610 - val_acc: 0.5579\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 0s 260us/step - loss: 1.2700 - acc: 0.5381 - val_loss: 1.2659 - val_acc: 0.5579\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 0s 258us/step - loss: 1.2707 - acc: 0.5381 - val_loss: 1.2561 - val_acc: 0.5579\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 278us/step - loss: 1.2704 - acc: 0.5381 - val_loss: 1.2788 - val_acc: 0.5579\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 0s 265us/step - loss: 1.2702 - acc: 0.5381 - val_loss: 1.2646 - val_acc: 0.5579\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 0s 249us/step - loss: 1.2690 - acc: 0.5381 - val_loss: 1.2784 - val_acc: 0.5579\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 0s 252us/step - loss: 1.2697 - acc: 0.5381 - val_loss: 1.2684 - val_acc: 0.5579\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 0s 250us/step - loss: 1.2699 - acc: 0.5381 - val_loss: 1.2575 - val_acc: 0.5579\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 0s 243us/step - loss: 1.2690 - acc: 0.5381 - val_loss: 1.2722 - val_acc: 0.5579\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 254us/step - loss: 1.2690 - acc: 0.5381 - val_loss: 1.2583 - val_acc: 0.5579\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 0s 264us/step - loss: 1.2692 - acc: 0.5381 - val_loss: 1.2698 - val_acc: 0.5579\n",
      "Epoch 14/20\n",
      "1366/1366 [==============================] - 0s 254us/step - loss: 1.2692 - acc: 0.5381 - val_loss: 1.2669 - val_acc: 0.5579\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 0s 245us/step - loss: 1.2695 - acc: 0.5381 - val_loss: 1.2700 - val_acc: 0.5579\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 0s 254us/step - loss: 1.2688 - acc: 0.5381 - val_loss: 1.2703 - val_acc: 0.5579\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 0s 250us/step - loss: 1.2691 - acc: 0.5381 - val_loss: 1.2673 - val_acc: 0.5579\n",
      "Epoch 18/20\n",
      "1366/1366 [==============================] - 0s 257us/step - loss: 1.2691 - acc: 0.5381 - val_loss: 1.2787 - val_acc: 0.5579\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 260us/step - loss: 1.2688 - acc: 0.5381 - val_loss: 1.2646 - val_acc: 0.5579\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 0s 253us/step - loss: 1.2693 - acc: 0.5381 - val_loss: 1.2532 - val_acc: 0.5579\n",
      "1608/1608 [==============================] - 0s 41us/step\n",
      "Accuracy: 54.10\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Case 2 : Trying an L1 regularization\n",
    "\n",
    "#from keras import regularizers\n",
    "#from matplotlib import pyplot\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('./stocknews/Combined_News_DJIA.csv')\n",
    "# split into input (X) and output (y) variables\n",
    "# define the keras model\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(64, input_dim=400, activation='relu'))\n",
    "model4.add(Dropout(0.05))\n",
    "model4.add(Dense(48, activation='relu', kernel_regularizer=regularizers.l1(1) ))\n",
    "model4.add(Dropout(0.05))\n",
    "model4.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l1(1)))\n",
    "model4.add(Dropout(0.05))\n",
    "model4.add(Dense(2, activation='softmax'))\n",
    "# compile the keras model\n",
    "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "history=model4.fit(X_train, Y_train, epochs=20, batch_size=10, validation_split= 0.15)\n",
    "#model.fit(X_train, Y_train, nb_epoch=2, batch_size=16, validation_split=0.15)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model4.evaluate(X_train, Y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print(history.history.keys())\n",
    "#plotting accuracy\n",
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 56us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2606381474348602, 0.5079365098287189]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1366 samples, validate on 242 samples\n",
      "Epoch 1/20\n",
      "1366/1366 [==============================] - 2s 1ms/step - loss: 1.2586 - acc: 0.5227 - val_loss: 0.9431 - val_acc: 0.5579\n",
      "Epoch 2/20\n",
      "1366/1366 [==============================] - 0s 300us/step - loss: 0.8281 - acc: 0.5432 - val_loss: 0.7505 - val_acc: 0.5579\n",
      "Epoch 3/20\n",
      "1366/1366 [==============================] - 1s 394us/step - loss: 0.7242 - acc: 0.5373 - val_loss: 0.7052 - val_acc: 0.5579\n",
      "Epoch 4/20\n",
      "1366/1366 [==============================] - 1s 401us/step - loss: 0.6995 - acc: 0.5381 - val_loss: 0.6945 - val_acc: 0.5579\n",
      "Epoch 5/20\n",
      "1366/1366 [==============================] - 1s 380us/step - loss: 0.6948 - acc: 0.5381 - val_loss: 0.6922 - val_acc: 0.5579\n",
      "Epoch 6/20\n",
      "1366/1366 [==============================] - 0s 340us/step - loss: 0.6892 - acc: 0.5395 - val_loss: 0.6919 - val_acc: 0.5579\n",
      "Epoch 7/20\n",
      "1366/1366 [==============================] - 1s 507us/step - loss: 0.6896 - acc: 0.5388 - val_loss: 0.6921 - val_acc: 0.5579\n",
      "Epoch 8/20\n",
      "1366/1366 [==============================] - 1s 476us/step - loss: 0.6816 - acc: 0.5981 - val_loss: 0.6987 - val_acc: 0.5744\n",
      "Epoch 9/20\n",
      "1366/1366 [==============================] - 1s 389us/step - loss: 0.6635 - acc: 0.6493 - val_loss: 0.7084 - val_acc: 0.5207\n",
      "Epoch 10/20\n",
      "1366/1366 [==============================] - 0s 351us/step - loss: 0.6491 - acc: 0.6918 - val_loss: 0.7384 - val_acc: 0.5702\n",
      "Epoch 11/20\n",
      "1366/1366 [==============================] - 1s 423us/step - loss: 0.6075 - acc: 0.7416 - val_loss: 0.8187 - val_acc: 0.5455\n",
      "Epoch 12/20\n",
      "1366/1366 [==============================] - 0s 337us/step - loss: 0.5574 - acc: 0.7936 - val_loss: 0.8655 - val_acc: 0.5248\n",
      "Epoch 13/20\n",
      "1366/1366 [==============================] - 0s 338us/step - loss: 0.4944 - acc: 0.8389 - val_loss: 1.0017 - val_acc: 0.5331\n",
      "Epoch 14/20\n",
      "1366/1366 [==============================] - 0s 282us/step - loss: 0.4493 - acc: 0.8712 - val_loss: 1.1372 - val_acc: 0.5579\n",
      "Epoch 15/20\n",
      "1366/1366 [==============================] - 0s 275us/step - loss: 0.4035 - acc: 0.9019 - val_loss: 1.3067 - val_acc: 0.5331\n",
      "Epoch 16/20\n",
      "1366/1366 [==============================] - 0s 278us/step - loss: 0.3577 - acc: 0.9224 - val_loss: 1.3911 - val_acc: 0.5165\n",
      "Epoch 17/20\n",
      "1366/1366 [==============================] - 0s 292us/step - loss: 0.3435 - acc: 0.9224 - val_loss: 1.5617 - val_acc: 0.5248\n",
      "Epoch 18/20\n",
      "1366/1366 [==============================] - 1s 476us/step - loss: 0.2947 - acc: 0.9495 - val_loss: 1.7130 - val_acc: 0.5248\n",
      "Epoch 19/20\n",
      "1366/1366 [==============================] - 0s 348us/step - loss: 0.2893 - acc: 0.9458 - val_loss: 1.7783 - val_acc: 0.5372\n",
      "Epoch 20/20\n",
      "1366/1366 [==============================] - 0s 322us/step - loss: 0.2723 - acc: 0.9539 - val_loss: 1.8059 - val_acc: 0.5207\n",
      "1608/1608 [==============================] - 0s 54us/step\n",
      "Accuracy: 92.41\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model 3 seems best to compete with the default so trying the categorical_crossentropy\n",
    "#l2 =0.01\n",
    "model5 = Sequential()\n",
    "model5.add(Dense(100, input_dim=400, activation='relu'))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(48, activation='relu', kernel_regularizer=regularizers.l2(0.01) ))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model5.add(Dropout(0.5))\n",
    "model5.add(Dense(2, activation='softmax'))\n",
    "# compile the keras model\n",
    "model5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "history=model5.fit(X_train, Y_train, epochs=20, batch_size=10, validation_split= 0.15)\n",
    "#model.fit(X_train, Y_train, nb_epoch=2, batch_size=16, validation_split=0.15)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model5.evaluate(X_train, Y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print(history.history.keys())\n",
    "#plotting accuracy\n",
    "pyplot.plot(history.history['acc'], label='train')\n",
    "pyplot.plot(history.history['val_acc'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378/378 [==============================] - 0s 69us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.741166631380717, 0.5687830706752798]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evalauting the performance of model5\n",
    "model5.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 69,  46],\n",
       "       [117, 146]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building a confusion matrix to see prediction results\n",
    "y_pred5 = model5.predict(X_test)\n",
    "y_pred5 = np.argmax(y_pred5, axis=1)\n",
    "cm5 = confusion_matrix(y_pred5, y_test)\n",
    "cm5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 3 is the best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
